{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ0u0gf4fCcY"
   },
   "source": [
    "# Computer Vision and Deep Learning - Laboratory 3 \n",
    "\n",
    "Starting from this session, we'll be diving into deep convolutional neural networks and we'll start using _tensorflow_ a popular machine learning library developed by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BL1ip6vGgjp4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaIstjm6rI-0",
    "outputId": "6fb8f17b-9c8b-4908-e2ff-25f59f2b41f0"
   },
   "outputs": [],
   "source": [
    "# download an image that we'll be using at this lab\n",
    "!curl -X GET https://www.researchgate.net/profile/Paul-Rodriguez-5/publication/265988128/figure/fig1/AS:459614656438273@1486592081799/Input-test-images-a-Cameraman-grayscale-b-grayscale-Lena-and-c-color-Lena-All_Q640.jpg -O cameraman.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBatUXbIfOzt"
   },
   "source": [
    "# Warm-up\n",
    " \n",
    " \n",
    "Let's start by implementing the basic blocks of a convolutional neural network: the convolutional and the pooling operations. Perhaps this would be the last \"low-level\" implementation that you'll do for this laboratory.\n",
    " \n",
    "## Convolutions\n",
    " \n",
    "The convolutional layer is the main building block of a convolutional neural network. These layers contain a set of learnable filters, which will learn which features are relevant for the classification problem based on the training data.\n",
    "During the forward pass, each filter (which __must__ have the same depth as the input volume) is slided over the spatial dimensions of the input volume and we compute an element-wise multiplication between the filter weights and the region of interest in the input volume that lies beneath the filter.\n",
    " \n",
    "The hyperparameters of a convolutional layer are:\n",
    "- the filter size F (usually this is an odd value);\n",
    "- the padding amount which will be added to the input volume P;\n",
    "- the stride S (or the step used when sliding across the input volume);\n",
    "- the number of filters k; the depth of each filter must match the depth of the input volume;\n",
    " \n",
    "Given an input volume of shape  ($H_i$, $W_i$, $D$), the convolutional layer will produce an output of shape ($H_o$, $W_o$, $k$), where:\n",
    " \n",
    "\\begin{equation}\n",
    "W_o = \\frac{W_i - F + 2P}{S} + 1\n",
    "\\end{equation}\n",
    " \n",
    "\\begin{equation}\n",
    "H_o = \\frac{H_i - F + 2P}{S} + 1\n",
    "\\end{equation}\n",
    " \n",
    "<img src=\"https://lh6.googleusercontent.com/gZxwFH6mQ5tPjz6LzVbOaNeVuR1NC-BnuemIWO41qnn7r1PvP4qzwXRWC1OJgo2_PD08qaqJ2-VCF3q9laeK885IJwK-dHhpLDkvRZrx4vxrbLDTsKD2iZYM5SFRq4A6XTklk7_h\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qg10tJHJKVCT"
   },
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    This function applies the zero padding operation on all the images in the array X\n",
    "    :param X input array of images; this array has a of rank 4 (batch_size, height, width, channels)\n",
    "    :param pad the amount of zeros to be added around around the spatial size of the images\n",
    "    \"\"\"\n",
    "    # hint you might find the function numpy.pad useful for this purpose\n",
    "    # keep in mind that you only need to pad the spatial dimensions (height and width)\n",
    "    return np.pad(X, pad_width=((0, 0), (pad, pad), (pad, pad), (0, 0)))\n",
    "\n",
    "\n",
    "# load the image using Pillow\n",
    "img = Image.open('cameraman.jpg')\n",
    "img = np.asarray(img)\n",
    "img = np.asarray([img])\n",
    "img = np.stack([img], axis=3)\n",
    "img = zero_pad(img, 150)\n",
    "plt.imshow(img[0], cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmXz-pt7gFXn",
    "outputId": "d47d5cb1-3242-4c19-d0d0-60accc364a00"
   },
   "outputs": [],
   "source": [
    "def convolution(X, W, bias, pad, stride):\n",
    "    \"\"\"\n",
    "    This function applied to convolution operation on the input X of shape (num_samples, iH, iW, iC)\n",
    "    using the filters defined by the W (filter weights) and  (bias) parameters.\n",
    "\n",
    "    :param X - input of shape (num_samples, iH, iW, iC)\n",
    "    :param W - weights, numpy array of shape (fs, fs, iC, k), where fs is the filter size,\n",
    "      iC is the depth of the input volum and k is the number of filters applied on the image\n",
    "    :param biases - numpy array of shape (1, 1, 1, k)\n",
    "    :param pad - hyperparameter, the amount of padding to be applied\n",
    "    :param stride - hyperparameter, the stride of the convolution\n",
    "    \"\"\"\n",
    "\n",
    "    # 0. compute the size of the output activation map and initialize it with zeros\n",
    "\n",
    "    num_samples = X.shape[0]\n",
    "    iH = X.shape[1]\n",
    "    iW = X.shape[2]\n",
    "    f = W.shape[0]\n",
    "\n",
    "    H0 = int((iH - f + 2 * pad) / stride + 1)\n",
    "    W0 = int((iW - f + 2 * pad) / stride + 1)\n",
    "    k = W.shape[3]\n",
    "    activation_map = np.zeros((num_samples, H0, W0, k))\n",
    "\n",
    "    # 1. pad the samples in the input\n",
    "    X_padded = zero_pad(X, pad)\n",
    "\n",
    "    # go through each input sample\n",
    "    for i in range(num_samples):\n",
    "        X_i = X_padded[i]\n",
    "\n",
    "        # loop over the spatial dimensions\n",
    "        for y in range(H0):\n",
    "            # compute the current ROI in the image on which the filter will be applied (y dimension)\n",
    "            # tl_y - the y coordinate of the top left corner of the current region\n",
    "            # br_y - the y coordinate of the bottom right corner of the current region\n",
    "            tl_y = y * stride\n",
    "            br_y = y * stride + f\n",
    "\n",
    "            for x in range(W0):\n",
    "                # TODO your code here\n",
    "                # compute the current ROI in the image on which the filter will be applied (x dimension)\n",
    "                # tl_x - the x coordinate of the top left corner of the current region\n",
    "                # br_x - the x coordinate of the bottom right corner of the current region\n",
    "                tl_x = x * stride\n",
    "                br_x = x * stride + f\n",
    "                # end TODO your code here\n",
    "\n",
    "                for c in range(k):\n",
    "                    # select the current ROI on which the filter will be applied\n",
    "                    roi = X_i[tl_y: br_y, tl_x: br_x, :]\n",
    "                    w = W[:, :, :, c]\n",
    "                    b = bias[:, :, :, c]\n",
    "\n",
    "                    # TODO your code here\n",
    "                    # apply the filter with the weights w and bias b on the current image roi\n",
    "\n",
    "                    # A. compute the elemetwise product between roi and the weights of the filters (np.multiply)\n",
    "                    a = np.multiply(roi, w)\n",
    "                    # B. sum across all the elements of a\n",
    "                    a = np.sum(a)\n",
    "                    # C. add the bias term\n",
    "                    a = a + b\n",
    "\n",
    "                    # D. add the result in the appropriate position of the output activation map\n",
    "                    activation_map[i, y, x, c] = a\n",
    "                    # end TODO your code here\n",
    "                assert (activation_map.shape == (num_samples, H0, W0, k))\n",
    "    return activation_map\n",
    "\n",
    "\n",
    "np.random.seed(10)\n",
    "# 100 samples of shape (13, 21, 4)\n",
    "X = np.random.randn(100, 13, 21, 4)\n",
    "\n",
    "# 8 filters (last dimension) of shape (3, 3)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "\n",
    "am = convolution(X, W, b, pad=1, stride=2)\n",
    "print(\"am's mean =\\n\", np.mean(am))\n",
    "print(\"am[1, 2, 3] =\\n\", am[3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UN7Ig4gqIgl"
   },
   "source": [
    "Expected output: \n",
    "\n",
    "am's mean =\n",
    " -0.42841306\n",
    "\n",
    "am[1, 2, 3] =\n",
    " [ 1.780819  -6.5181394 -4.3581524 -2.9115834  1.8401672 -3.722643\n",
    " -8.327618  -3.227787 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tzYzhRAgF2n"
   },
   "source": [
    "Now let's analyse the effect of applying some well known filters used in image processing.\n",
    " \n",
    "### Low pass filters\n",
    "Low pass filters are used to keep the low frequency information within an, while reducing the high frequency information. These filters are the basis of image smoothing.\n",
    " \n",
    "Two well known low pass filters are the _mean filter_ and the _Gaussian filter_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2zrftQwuyjE"
   },
   "outputs": [],
   "source": [
    "# load the image using Pillow\n",
    "image = Image.open('cameraman.jpg')\n",
    "image = np.asarray(image)\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "# X contains a single image sample\n",
    "X = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "WbyFIs-3ghKb",
    "outputId": "b3f00763-a14b-450a-d12c-e421e4ca00f1"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# MEAN FILTER\n",
    "############################################################\n",
    "\n",
    "bias = np.asarray([0])\n",
    "bias = bias.reshape((1, 1, 1, 1))\n",
    "\n",
    "mean_filter_3 = np.ones(shape=(3, 3, 1, 1), dtype=np.float32)\n",
    "mean_filter_3 = mean_filter_3/9.0\n",
    "\n",
    "mean_filter_9 = np.ones(shape=(9, 9, 1, 1), dtype=np.float32)\n",
    "mean_filter_9 = mean_filter_9/81.0\n",
    "\n",
    "mean_3x3 = convolution(X, mean_filter_3, bias, pad=0, stride=1)\n",
    "mean_9x9 = convolution(X, mean_filter_9, bias, pad=0, stride=1)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.title('Original image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_3x3[0, :, :, 0], cmap='gray')\n",
    "plt.title('mean filter 3x3')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.title('Original image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_9x9[0, :, :, 0], cmap='gray')\n",
    "plt.title('mean filter 9x9')\n",
    "\n",
    "\n",
    "############################################################\n",
    "# GAUSSIAN FILTER\n",
    "############################################################\n",
    "\n",
    "gaussian_filter = np.asarray(\n",
    "    [[1, 2, 1],\n",
    "     [2, 4, 2],\n",
    "     [1, 2, 1]],\n",
    "     dtype=np.float32\n",
    ")\n",
    "gaussian_filter = gaussian_filter.reshape(3, 3, 1, 1)\n",
    "gaussian_filter = gaussian_filter/16.0\n",
    "\n",
    "gaussian_smoothed = convolution(X, gaussian_filter, bias, pad=0, stride=1)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.title('Original image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(gaussian_smoothed[0,:,:,0], cmap='gray')\n",
    "plt.title('Gaussian filtered')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2cfOfIWz3OJ"
   },
   "source": [
    "__Optional__: Now load a color image and apply the mean filtering and Gaussian filtering on this color image.\n",
    "Not much changes at the call of the convolution operation, you just need to \"play\" with the convolutional kernels configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrM5aNuGz91v"
   },
   "outputs": [],
   "source": [
    "# TODO your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_JHtqns1395"
   },
   "source": [
    "### High pass filters \n",
    "\n",
    "On the other hand, high pass filters are used to highlight the high frequency information in an image (edges, abrupt changes in intensities).\n",
    "\n",
    "One of the most commonly used high pass filters is the Sobel kernel (depicted below). These filters can be seen as discrete differentiation operators, and they compute an approximation of the gradient (on the horizontal or vertical direction) of the image intensity function.\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/W7OpxFbrD84/maxresdefault.jpg\" width=300px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "id": "l7gsvHVi2pwD",
    "outputId": "0ecedec6-c38a-4533-88a4-318b2fe4305a"
   },
   "outputs": [],
   "source": [
    "sobel_horiz = np.asarray([[-1, 0, 1],\n",
    "                          [-2, 0, 2], \n",
    "                          [-1, 0, 1]])\n",
    "\n",
    "sobel_vert = sobel_horiz.T \n",
    "\n",
    "sobel_horiz = np.reshape(sobel_horiz, (3, 3, 1, 1))\n",
    "sobel_vert = np.reshape(sobel_vert, (3, 3, 1, 1))\n",
    "\n",
    "sobel_x = convolution(X, sobel_horiz, bias, 0, 1)\n",
    "sobel_y = convolution(X, sobel_vert, bias, 0, 1)\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.title('Original image')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(np.abs(sobel_x[0,:,:,0])/np.abs(np.max(sobel_x[0,:,:,0]))*255, cmap='gray')\n",
    "plt.title('Sobel X')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.abs(sobel_y[0,:,:,0])/np.abs(np.max(sobel_y[0,:,:,0]))*255, cmap='gray')\n",
    "plt.title('Sobel Y')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heKTIeINgByi"
   },
   "source": [
    "## Pooling\n",
    "\n",
    "The pooling layer is used to reduce the spatial dimension of the activation maps, and thus the computational burden. It has no learnable parameters and it operates individually across each input channel and resizes it spatially.\n",
    "\n",
    "The two most common types of pooling are max pooling and average pooling.\n",
    "\n",
    "\n",
    "The hyperparameters of a pooling layer are:\n",
    "- the filter size F (usually this is an odd value);\n",
    "- the stride S (or the step used when sliding across the input volume);\n",
    "\n",
    "Given an input volume of shape  ($H_i$, $W_i$, $D$), the convolutional layer will produce an output of shape ($H_o$, $W_o$, $D$), where:\n",
    "\n",
    "\\begin{equation}\n",
    "W_o = \\frac{W_i - F}{S} + 1\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "H_o = \\frac{H_i - F}{S} + 1\n",
    "\\end{equation}\n",
    "\n",
    "An illustration of the pooling operation is depicted in the image below:\n",
    "\n",
    "![picture](https://www.researchgate.net/profile/Alla-Eddine-Guissous/publication/337336341/figure/fig15/AS:855841334898691@1581059883782/Example-for-the-max-pooling-and-the-average-pooling-with-a-filter-size-of-22-and-a.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t81pBIwF5lzv"
   },
   "outputs": [],
   "source": [
    "def pooling(X, filter_size, stride, type):\n",
    "    \"\"\"\n",
    "    Implements the pooling operation\n",
    "\n",
    "    :param X - input volume of shape (num_samples, H, W, C)\n",
    "    :param filter_size - the size of the pooling\n",
    "    :param stride - the stride of the pooling operation\n",
    "    :param type - can be 'max' or 'avg'; the type of the pooling operation to apply\n",
    "\n",
    "    Returns the output of the pooling operation.\n",
    "    \"\"\"\n",
    "    pool_function = np.max if type == \"max\" else np.average\n",
    "\n",
    "    num_samples = X.shape[0]\n",
    "    iH = X.shape[1]\n",
    "    iW = X.shape[2]\n",
    "\n",
    "    W0 = int((iW - filter_size) / stride) + 1\n",
    "    H0 = int((iH - filter_size) / stride) + 1\n",
    "    C0 = X.shape[3]\n",
    "\n",
    "    activation_map = np.zeros((num_samples, H0, W0, C0))\n",
    "    for i in range(num_samples):\n",
    "        for y in range(H0):\n",
    "            tl_y = y * stride\n",
    "            br_y = y * stride + filter_size\n",
    "            for x in range(W0):\n",
    "                tl_x = x * stride\n",
    "                br_x = x * stride + filter_size\n",
    "                for c in range(C0):\n",
    "                    roi = X[i, tl_y: br_y, tl_x: br_x, c]\n",
    "                    activation_map[i, y, x, c] = pool_function(roi)\n",
    "    assert (activation_map.shape == (num_samples, H0, W0, C0))\n",
    "    return activation_map\n",
    "\n",
    "\n",
    "def get_pooled_image(image_path, filter_size, stride, test_type):\n",
    "    image = Image.open(image_path)\n",
    "    image = np.asarray(image)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    X = np.expand_dims(image, axis=0)\n",
    "    return pooling(X, filter_size, stride, test_type)[0].astype(int)\n",
    "\n",
    "plt.figure(figsize=(16, 16), dpi=80)\n",
    "plt.subplot(4, 4, 1)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 4, 4, 'max'), cmap='gray')\n",
    "plt.subplot(4, 4, 2)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 16, 16, 'max'), cmap='gray')\n",
    "plt.subplot(4, 4, 3)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 8, 16, 'max'), cmap='gray')\n",
    "plt.subplot(4, 4, 4)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 16, 8, 'max'), cmap='gray')\n",
    "plt.subplot(4, 4, 5)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 4, 4, 'avg'), cmap='gray')\n",
    "plt.subplot(4, 4, 6)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 16, 16, 'avg'), cmap='gray')\n",
    "plt.subplot(4, 4, 7)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 8, 16, 'avg'), cmap='gray')\n",
    "plt.subplot(4, 4, 8)\n",
    "plt.imshow(get_pooled_image('cameraman.jpg', 16, 8, 'avg'), cmap='gray')\n",
    "plt.subplot(4, 4, 9)\n",
    "plt.imshow(get_pooled_image('face.jpg', 4, 4, 'max'))\n",
    "plt.subplot(4, 4, 10)\n",
    "plt.imshow(get_pooled_image('face.jpg', 16, 16, 'max'))\n",
    "plt.subplot(4, 4, 11)\n",
    "plt.imshow(get_pooled_image('face.jpg', 8, 16, 'max'))\n",
    "plt.subplot(4, 4, 12)\n",
    "plt.imshow(get_pooled_image('face.jpg', 16, 8, 'max'))\n",
    "plt.subplot(4, 4, 13)\n",
    "plt.imshow(get_pooled_image('face.jpg', 4, 4, 'avg'))\n",
    "plt.subplot(4, 4, 14)\n",
    "plt.imshow(get_pooled_image('face.jpg', 16, 16, 'avg'))\n",
    "plt.subplot(4, 4, 15)\n",
    "plt.imshow(get_pooled_image('face.jpg', 8, 16, 'avg'))\n",
    "plt.subplot(4, 4, 16)\n",
    "plt.imshow(get_pooled_image('face.jpg', 16, 8, 'avg'))\n",
    "\n",
    "# TODO your code here\n",
    "# apply the pooling operation on a grayscale image and on a color image\n",
    "# try different values for the stride and filter size. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJnU5vvafZQD"
   },
   "source": [
    "# Hello, _tensorflow_!\n",
    "\n",
    "Follow [this tutorial](https://www.tensorflow.org/tutorials/images/cnn) to build your first convolutional neural network using a sequential model in a few lines of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfZCJu-6UN4m"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.ylim([0, 1])\n",
    "    plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=32,\n",
    "                    validation_data=(test_images, test_labels))\n",
    "print(\"History of the basic version\")\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "model.save(f\"./weights/test_acc_{str(test_acc)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Added He initializer\")\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        padding=\"same\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,\n",
    "                       kernel_initializer=initializer,\n",
    "                       activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history =  model.fit(train_images, train_labels, epochs=10, batch_size=32,\n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "model.save(f\"./weights/test_acc_{str(test_acc)[:4]}_with_he_initializer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Added regularization\")\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "regularizer = tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,\n",
    "                       kernel_initializer=initializer,\n",
    "                       kernel_regularizer=regularizer,\n",
    "                       bias_regularizer=regularizer,\n",
    "                       activity_regularizer=regularizer,\n",
    "                       activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history =  model.fit(train_images, train_labels, epochs=10, batch_size=32,\n",
    "                     validation_data=(test_images, test_labels))\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "model.save(f\"./weights/test_acc_{str(test_acc)[:5]}_with_regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Added dropout\")\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "regularizer = tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,\n",
    "                       kernel_initializer=initializer,\n",
    "                       kernel_regularizer=regularizer,\n",
    "                       bias_regularizer=regularizer,\n",
    "                       activity_regularizer=regularizer,\n",
    "                       activation='relu'))\n",
    "model.add(layers.Dropout(.5))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history =  model.fit(train_images, train_labels, epochs=10, batch_size=32,\n",
    "                     validation_data=(test_images, test_labels))\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "model.save(f\"./weights/test_acc_{str(test_acc)[:5]}_with_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2.cv2 as cv2\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "def clip(x, left, right):\n",
    "    return max(left, min(x, right))\n",
    "\n",
    "def cutout(x, cropSize):\n",
    "    cut_x = x\n",
    "    shape = x.get_shape()\n",
    "\n",
    "    mask = np.ones(shape)\n",
    "    x_coord = np.random.randint(0, shape[0])\n",
    "    y_coord = np.random.randint(0, shape[1])\n",
    "    tl_x = clip(x_coord-cropSize, 0,shape[0])\n",
    "    tl_y = clip(y_coord-cropSize, 0, shape[1])\n",
    "    br_x = clip(x_coord+cropSize, 0, shape[0])\n",
    "    br_y = clip(y_coord+cropSize, 0,  shape[1])\n",
    "    mask[tl_x:br_x, tl_y:br_y, :] = np.zeros((br_x-tl_x, br_y-tl_y, shape[2]))\n",
    "    cut_x = tf.where(tf.convert_to_tensor(mask, dtype=tf.bool), cut_x, 0)\n",
    "    return cut_x\n",
    "\n",
    "class Cutout(layers.Layer):\n",
    "    def __init__(self, cropSize, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cropSize = cropSize # cropped region will be cropSize*2+1\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if not training:\n",
    "            return x\n",
    "        return tf.map_fn(lambda elem: cutout(elem, self.cropSize), x)\n",
    "\n",
    "class CutoutModel(tf.keras.Model):\n",
    "    def __init__(self, cropSize, input_shape):\n",
    "        super(CutoutModel, self).__init__(name='')\n",
    "        self.cutout = Cutout(cropSize, input_shape= input_shape)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = input_tensor\n",
    "        if training:\n",
    "            x = self.cutout(input_tensor)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('face.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (500, 500))\n",
    "# X contains a single image sample\n",
    "X = np.stack([image]*32)\n",
    "print(X.shape)\n",
    "cut_X = Cutout(100)(tf.convert_to_tensor(X), training=True)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(cut_X[0])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(cut_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Added cutout...\")\n",
    "\n",
    "cutoutValue = 5\n",
    "print(f\"Cutout value: {cutoutValue}\")\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "regularizer = tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Cutout(cutoutValue))\n",
    "model.add(layers.Conv2D(32, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        kernel_initializer=initializer,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        bias_regularizer=regularizer,\n",
    "                        activity_regularizer=regularizer,\n",
    "                        padding=\"same\", activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,\n",
    "                       kernel_initializer=initializer,\n",
    "                       kernel_regularizer=regularizer,\n",
    "                       bias_regularizer=regularizer,\n",
    "                       activity_regularizer=regularizer,\n",
    "                       activation='relu'))\n",
    "model.add(layers.Dropout(.5))\n",
    "model.add(layers.Dense(10))\n",
    "model.build(input_shape=(None, 32,32,3))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history =  model.fit(train_images, train_labels, epochs=10, batch_size=32,\n",
    "                     validation_data=(test_images, test_labels))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "model.save(f\"./weights/test_acc_{str(test_acc)[:5]}_with_cutout\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yBZGbkx1kQX"
   },
   "source": [
    "This was pretty easy!  In the next laboratory we'll look at a basic \"recipe\" on how we can effectively tune the hyperparameters of a network, but for now let's just get familiar with _tensorflow_ and see how we can modify some parameters of this vanilla network.\n",
    "\n",
    "- First of all, move the model.summary() call at the end of your model creation (after the last dense layer) and analyse the number of parameters of each layer.\n",
    "- [Serialize](https://www.tensorflow.org/guide/keras/save_and_serialize) your model after training.\n",
    "- Change the initializers of the layers with ReLu activations to [He initializer](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal). Retrain and save the results.\n",
    "- Add some [regularization](https://keras.io/api/layers/regularizers/) to your network. Retrain and save the results.\n",
    "- Add a [dropout layer](https://keras.io/api/layers/regularization_layers/dropout/) after the layer with the highest number of parameters and retrain your network. Retrain and save the results.\n",
    "\n",
    "Plot the learning curver for all teh training that you performed.\n",
    "Create a table to compare the accuracy of your trained models.\n",
    "\n",
    "| Colum1      | Column2 |\n",
    "| ----------- | ----------- |\n",
    "| Cell11      | Cell12      |\n",
    "| Cell21      | Cell22      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHhplFud9ixf"
   },
   "source": [
    "## Writing a custom layer\n",
    " \n",
    "As you observed, when using _tensorflow_ you work at a high level of abstraction via layers. In other words, you don't need to get your hands dirty by manipulating variables, and usually you just stack several layers on top of each other to build your models.\n",
    " \n",
    "_tensorflow_ provides by default many layers commonly used in machine learning, but it also provides you an easy way to write your custom layers based on your needs. These layers can be written  from scratch or as the composition of several existing layers.\n",
    " \n",
    "To implement a custom layer you just need to extend from _tf.keras.Layer_ and implement the following methods:\n",
    "- \\_\\_init__(), where you can do all input-independent initialization;\n",
    "- build(), where you know the shapes of the input tensors and can do the rest of the initialization; you can as well create all the variables in the constructor, but  the advantage of creating them in build is that it enables late variable creation based on the shape of the inputs the layer will operate on;\n",
    "- call(), where you do the forward computation of that layer\n",
    " \n",
    "In the last part of the laboratory you will implement a custom image augmentation layer, namely [_cutout_](https://arxiv.org/pdf/1708.04552.pdf). \n",
    " \n",
    "Cutout is a very simple augmentation that can boost your test accuracy with more than 1%. \n",
    " \n",
    "\"_Cutout is a simple regularization technique for convolutional neural networks that involves removing contiguous\n",
    "sections of input images, effectively augmenting the dataset\n",
    "with partially occluded versions of existing samples. This\n",
    "technique can be interpreted as an extension of dropout in\n",
    "input space, but with a spatial prior applied, much in the\n",
    "same way that CNNs apply a spatial prior to achieve improved performance over feed-forward networks on image\n",
    "data._\"\n",
    " \n",
    "## Implementation details (text from the original cutout paper)\n",
    "\"_To implement cutout, we simply apply a fixed-size zeromask to a random location of each input image during each\n",
    "epoch of training._\n",
    " \n",
    "<img src=\"https://raw.githubusercontent.com/xkumiyu/numpy-data-augmentation/master/data/output/cutout.jpg\" width=200px/>\n",
    " \n",
    "_When cutout is applied to an image, we randomly select a pixel coordinate within the image\n",
    "as a center point and then place the cutout mask around that\n",
    "location. \n",
    "This method allows for the possibility that not all\n",
    "parts of the cutout mask are contained within the image. Interestingly, we found that allowing portions of the patches\n",
    "to lay outside the borders of the image (rather than constraining the entire patch to be within the image) was critical to achieving good performance._\"\n",
    " \n",
    "You can follow [this](https://www.tensorflow.org/tutorials/images/data_augmentation#custom_data_augmentation) tutorial to see how you can write a custom data augmentation layer.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfIoVPUnIZK8"
   },
   "source": [
    "Please take some time to complete this feedback [from](https://docs.google.com/forms/d/1MezmHGuHUh1B40gm2HZMR_HdFaXZrGne7QyBQJPKGmc/edit). Thanks!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Computer Vision and Deep Learning - Laboratory 3 [students].ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a84fd92db5a471e91f372cecb47adab54dcdef527b642916ca90b59569abdda0"
  },
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
